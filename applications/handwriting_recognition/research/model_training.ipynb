{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the jupyter notebook generated from the Edge Impulse website. It contains a couple of helper functions as well as all the code showing the model hyperparameters for training and tuning.\n",
    "\n",
    "Import the data from Edge Impulse. You can obtain the URL from the Dashboard, right-click on the download icon next to 'Spectral features data' and 'Spectral features labels', and click **Copy link location**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "API_KEY = 'my_private_api_key'\n",
    "\n",
    "X = (requests.get('https://studio.edgeimpulse.com/v1/api/17190/training/28/x', headers={'x-api-key': API_KEY})).content\n",
    "Y = (requests.get('https://studio.edgeimpulse.com/v1/api/17190/training/28/y', headers={'x-api-key': API_KEY})).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data in a temporary file, and load it back through Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.npy', 'wb') as file:\n",
    "    file.write(X)\n",
    "with open('y_train.npy', 'wb') as file:\n",
    "    file.write(Y)\n",
    "X = np.load('x_train.npy')\n",
    "Y = np.load('y_train.npy')[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our labels and split the data up in a test and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Set random seeds for repeatable results\n",
    "RANDOM_SEED = 3\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "classes_values = [ \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"noise\" ]\n",
    "classes = len(classes_values)\n",
    "\n",
    "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "input_length = X_train[0].shape[0]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "def set_batch_size(batch_size, train_dataset, validation_dataset):\n",
    "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "callbacks = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Reshape((1, 200, 3), input_shape=(input_length, )))\n",
    "model.add(Conv2D(8, kernel_size=(1,9), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(16, kernel_size=(1,6), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(32, kernel_size=(1,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(64, kernel_size=(1,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu',\n",
    "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
    "model.add(Dense(classes, activation='softmax', name='y_pred'))\n",
    "\n",
    "# this controls the learning rate\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
    "BATCH_SIZE = 32\n",
    "train_dataset, validation_dataset = set_batch_size(BATCH_SIZE, train_dataset, validation_dataset)\n",
    "callbacks.append(EarlyStopping(patience=10, restore_best_weights=True))\n",
    "\n",
    "# train the neural network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=5000, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Reshape((1, 200, 3), input_shape=(600, )))\n",
    "model.add(Conv2D(8, kernel_size=(1,9), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(16, kernel_size=(1,6), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(32, kernel_size=(1,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(64, kernel_size=(1,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu',\n",
    "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
    "model.add(Dense(classes, activation='softmax', name='y_pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
